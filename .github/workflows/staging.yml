name: Build & Staging
on:
  push:
    branches:
      - develop

env:
  CONTAINER_REGISTRY: ghcr.io
  CONTAINER_REGISTRY_USER: ${{ secrets.GHCR_CONTAINER_REGISTRY_USER }}
  CONTAINER_REGISTRY_PASSWORD: ${{ secrets.GHCR_TOKEN }}
  CONTAINER_REGISTRY_REPO: ghcr.io/city-of-helsinki/${{ github.event.repository.name }}
  REPO_NAME: ${{ github.event.repository.name }}
  KUBECONFIG_RAW: ${{ secrets.KUBECONFIG_RAW_STAGING }}
  BUILD_ARTIFACT_FOLDER: "build_artifacts"
  SERVICE_ARTIFACT_FOLDER: "service_artifacts"
  BASE_DOMAIN: ${{ secrets.BASE_DOMAIN_STAGING }}
  ES_HOST: ${{ secrets.K8S_SECRET_ELASTICSEARCH_HOST_STAGING }}
  ES_PORT: ${{ secrets.K8S_SECRET_ELASTICSEARCH_PORT_STAGING }}
  ES_USERNAME: ${{ secrets.K8S_SECRET_ELASTICSEARCH_USERNAME_STAGING }}
  ES_PASSWORD: ${{ secrets.K8S_SECRET_ELASTICSEARCH_PASSWORD_STAGING }}
  K8S_REQUEST_CPU: 150m
  K8S_REQUEST_RAM: 200Mi
  K8S_LIMIT_CPU: 300m
  K8S_LIMIT_RAM: 300Mi
  DEBUG: 0
  PLAYGROUND: 1
  EVENT_URL: https://linkedevents-api.dev.hel.ninja/linkedevents-dev/v1/event/

jobs:
  build:
    strategy:
      fail-fast: false
      matrix:
        service: ["sources", "graphql"]

    runs-on: ubuntu-latest
    name: Build ${{ matrix.service }}
    steps:
      - uses: actions/checkout@v2
      - name: Build ${{ matrix.service }}
        uses: andersinno/kolga-build-action@v2
        env:
          DOCKER_BUILD_SOURCE: ./${{ matrix.service }}/Dockerfile
          DOCKER_BUILD_CONTEXT: ./${{ matrix.service }}
          DOCKER_IMAGE_NAME: ${{ matrix.service }}
          DOCKER_BUILD_ARG_DEBUG: "debug"

  staging:
    needs: build

    strategy:
      fail-fast: false
      matrix:
        service: ["sources", "graphql"]
        include:
          - service: "sources"
          - service: "graphql"
            SERVICE_PORT: "4000"

    runs-on: ubuntu-latest
    name: Deploy ${{ matrix.service }}

    steps:
      - uses: actions/checkout@v2
      - uses: andersinno/kolga-setup-action@v2

      - name: Misc variables
        run: |
          echo "K8S_SECRET_DEBUG=${{ env.DEBUG }}" >> $GITHUB_ENV

      - name: Elasticsearch variables
        run: |
          echo "K8S_SECRET_ES_URI=https://${{ env.ES_USERNAME }}:${{ env.ES_PASSWORD }}@${{ env.ES_HOST }}:${{ env.ES_PORT }}" >> $GITHUB_ENV

      - name: File probes
        if: matrix.SERVICE_PORT == ''
        run: |
          echo "K8S_LIVENESS_FILE=/app/ready.txt" >> $GITHUB_ENV
          echo "K8S_READINESS_FILE=/app/ready.txt" >> $GITHUB_ENV
          echo "K8S_INGRESS_DISABLED=True" >> $GITHUB_ENV

      - name: Service with ingress
        if: matrix.SERVICE_PORT != ''
        run: |
          echo "ENVIRONMENT_URL=https://unified-search.${{ env.BASE_DOMAIN }}" >> $GITHUB_ENV
          echo "SERVICE_PORT=${{ matrix.SERVICE_PORT }}" >> $GITHUB_ENV
          echo "K8S_SECRET_ALLOWED_HOSTS=*" >> $GITHUB_ENV

      - name: Sources settings
        if: matrix.service == 'sources'
        env:
          SECRET_KEY: ${{ secrets.K8S_SECRET_SECRET_KEY_STAGING }}
        run: |
          echo "K8S_SECRET_SECRET_KEY=$SECRET_KEY" >> $GITHUB_ENV

      - name: Deploy ${{ matrix.service }}
        uses: andersinno/kolga-deploy-action@v2
        with:
          track: "staging"
        env:
          DOCKER_BUILD_SOURCE: ./${{ matrix.service }}/Dockerfile
          DOCKER_BUILD_CONTEXT: ./${{ matrix.service }}
          DOCKER_IMAGE_NAME: ${{ matrix.service }}
          PROJECT_NAME: ${{ matrix.service }}
          K8S_NAMESPACE: ${{ secrets.K8S_NAMESPACE_STAGING }}

  cron:
    needs: staging
    runs-on: ubuntu-latest
    name: Deploy cronjob

    steps:
      - name: Deploy Cronjob
        uses: City-of-Helsinki/setup-cronjob-action@main
        with:
          name: harvester
          image_repository: ghcr.io/city-of-helsinki/${{ github.event.repository.name }}/sources
          image_tag:  ${{ github.sha }}
          secret_name: project-staging-sources-secret
          kubeconfig_raw: ${{ env.KUBECONFIG_RAW}}
          target_namespace: ${{ secrets.K8S_NAMESPACE_STAGING }}
          schedule: '0 3 * * *' # at 03:00 every day
          max_duration: "7200" # Run maximum 2 hours
          command: "{/bin/sh}"
          args: "{-c,python manage.py ingest_data --index location --delete && python manage.py ingest_data --index location}"
